{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import timeit\n",
    "import numpy as np\n",
    "import cv2\n",
    "import match_detector as orb  # code from assignment 7\n",
    "from visualizer import draw_output, draw_matches\n",
    "from obstacle_detector import ObstacleDetector\n",
    "from moviepy.editor import VideoFileClip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingTest(object):\n",
    "\n",
    "    \"\"\" Extends all pieces needed for experimentation.\n",
    "\n",
    "    Test case for video, consecutive images can be implemented.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cap_dev, tracker, visualation, dist_thresh, debug=False):\n",
    "        self.cap = cv2.VideoCapture(cap_dev)\n",
    "        self.no_of_frames = self.cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "        self.orb = tracker()\n",
    "        self.template = cv2.imread('/Users/dhruvarora/gt-cp-2017-project/visual_looming/raid_template.jpg')\n",
    "        self.visual = visualation\n",
    "        self.debug = debug\n",
    "        self.dist_thresh = dist_thresh\n",
    "        self.setup_camera()\n",
    "        self.template_cap_time = None\n",
    "\n",
    "    def setup_camera(self, width=1280, height=720, fps=10):\n",
    "        \"\"\" To configure for specific cam.\n",
    "\n",
    "        Params:\n",
    "            width: Width dimension of video capture.\n",
    "            height: Height dimension of video capture.\n",
    "            fps: Frame per seconds attribute setting for video capture.\n",
    "        Note: Defaults set for Intel Realsense camera\n",
    "        \"\"\"\n",
    "        # Slow down fps for debugging.\n",
    "        fps = 1 if self.debug else fps\n",
    "\n",
    "        self.cap.set(3, width)   # width\n",
    "        self.cap.set(4, height)  # height\n",
    "        self.cap.set(5, fps)     # fps\n",
    "        self.cap.set(16, 1)      # convert RGB\n",
    "\n",
    "    def update_template(self):\n",
    "        \"\"\" Updates the template captured from video.\n",
    "\n",
    "        Note: this function would be useful for real time update\n",
    "        of the template and multi instance version of application.\n",
    "        \"\"\"\n",
    "        for i in range(30):\n",
    "            ret, temp = self.cap.read()\n",
    "        #plt.imshow(temp)\n",
    "        #self.cap.release()\n",
    "        if ret:\n",
    "            self.template = temp\n",
    "            plt.imshow(self.template)\n",
    "            print (\"template captured\")\n",
    "            return self.template\n",
    "        else:\n",
    "            print (\"template update failed\")\n",
    "            return None\n",
    "\n",
    "    def process_next_image(self, img):\n",
    "        \n",
    "        \"\"\" Process input image and template to get matches using tracking algorithm.\n",
    "\n",
    "        Params:\n",
    "            img: New image frame.\n",
    "        Returns:\n",
    "            Matched image with the template\n",
    "\n",
    "        Note: image 1 = current image, image 2 = previous image.\n",
    "        \"\"\"\n",
    "        self.orb.find_matches_between(img, self.template)\n",
    "        \n",
    "        self.orb.discard_miss_match(threshold=self.dist_thresh)\n",
    "        self.orb.discard_size_thresh()\n",
    "\n",
    "        detector = ObstacleDetector(\n",
    "            img, self.template, self.orb.matches, self.orb.kp1, self.orb.kp2)\n",
    "        detector.confirm_scale()\n",
    "        \n",
    "        \n",
    "        output = np.copy(img)\n",
    "       \n",
    "        if detector.matches:\n",
    "            \n",
    "            # find speed of approaching object.\n",
    "            # assuming that object becomes 1.5 times larger when comes from 3\n",
    "            # meters to 2 meters.\n",
    "            time_since_template_captured = timeit.default_timer(\n",
    "            ) - self.template_cap_time\n",
    "            avg_scale = np.mean(np.array(detector.obstacle_scale, dtype=float))\n",
    "            dist_traveled = avg_scale / 1.5\n",
    "            speed = dist_traveled / time_since_template_captured\n",
    "            speed = float(\"{0:.2f}\".format(speed)) * 100\n",
    "\n",
    "            \n",
    "            \n",
    "            # add speed overlay\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "            output = cv2.putText(\n",
    "                output, 'Obstacle_speed: ' +\n",
    "                    str(speed) + \" cm/s \", (10, 30), font, 1, (200, 255, 155),\n",
    "                                 2,\n",
    "                                 cv2.LINE_AA)\n",
    "\n",
    "            obstacle = detector.get_obstacle_position()\n",
    "            cv2.circle(output, obstacle, 5, (0, 255, 0), thickness=5)\n",
    "            cv2.circle(self.template, obstacle, 5, (0, 255, 0), thickness=5)\n",
    "            #print('inside process_image')\n",
    "            draw_output(\n",
    "                self.orb.matches, detector.matches, self.orb.kp1, output)\n",
    "            #plt.imshow(output)\n",
    "        annotated_matches = None\n",
    "        annotated_matches = self.visual(\n",
    "            output, self.orb.kp1, self.template, self.orb.kp2, detector.matches,\n",
    "            annotated_matches, flags=2)\n",
    "\n",
    "        return annotated_matches\n",
    "\n",
    "    def skip_frames(self, frames):\n",
    "        \"\"\" Set to skip few frames from the webcam.\n",
    "\n",
    "        Params:\n",
    "            frames: Number of frames to skip.\n",
    "        \"\"\"\n",
    "        for i in range(frames):\n",
    "            ret, template = self.cap.read()\n",
    "\n",
    "    def grab_next_img(self):\n",
    "        \"\"\" Function to grab next image from self.cap.\n",
    "\n",
    "        Returns:\n",
    "            frame: Returns capture frame, else None.\n",
    "        \"\"\"\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            return frame\n",
    "        else:\n",
    "            return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_video(video, dist_thresh, skip, debug=False):\n",
    "    \"\"\" Setup method to setup everything on the video file input\n",
    "\n",
    "     Params:\n",
    "        video: Video file to read.\n",
    "        dist_thresh: Threshold passed to orb tracker to filter matches.\n",
    "        skip: # of frames to skip for processing.\n",
    "        debug: Set to True if in debug environment.\n",
    "    \"\"\"\n",
    "    test = TrackingTest(video, orb.OrbTracker,\n",
    "                        cv2.drawMatches, dist_thresh=dist_thresh, debug=True)\n",
    "    #print(test.no_of_frames)\n",
    "    #test.skip_frames()\n",
    "    #test.update_template()\n",
    "    test.template_cap_time = timeit.default_timer()\n",
    "    \n",
    "    \n",
    "    avg_fps = 0\n",
    "    fps_records = []\n",
    "    \n",
    "    elapsed = 0\n",
    "    fps = 5\n",
    "    while test.cap.isOpened():\n",
    "        test.skip_frames(int(fps * elapsed))\n",
    "        # test.skip_frames(skip)\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        ret, img = test.cap.read()\n",
    "        if ret:\n",
    "            match = test.process_next_image(img)\n",
    "            cv2.imshow(\"matches\", match)\n",
    "            cv2.waitKey(1)\n",
    "            elapsed = timeit.default_timer() - start_time\n",
    "            fps_records.append(elapsed)\n",
    "            avg_fps = 1.0 / (np.mean(np.array(fps_records, dtype=np.float)))\n",
    "            print (\"time for loop \", elapsed, \"avg fps \", avg_fps)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            test.cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    #return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for loop  2.129150828001002 avg fps  0.469670812818\n",
      "time for loop  1.7187228759976279 avg fps  0.519767579149\n",
      "time for loop  1.3539733899997373 avg fps  0.576718220622\n",
      "time for loop  1.8919316220017208 avg fps  0.563874369379\n",
      "time for loop  1.6591610300019966 avg fps  0.571236652495\n",
      "time for loop  1.4339047870016657 avg fps  0.588994951338\n",
      "time for loop  1.5781028179990244 avg fps  0.594987787974\n",
      "time for loop  1.6734013300010702 avg fps  0.595311238747\n",
      "time for loop  1.4652434130002803 avg fps  0.603881261862\n",
      "time for loop  1.509961226998712 avg fps  0.609252597803\n",
      "time for loop  2.0404773660011415 avg fps  0.596075740123\n",
      "time for loop  1.5118359370026155 avg fps  0.601025751899\n",
      "time for loop  1.450559125001746 avg fps  0.607010719359\n",
      "time for loop  1.5170822279978893 avg fps  0.610460467454\n",
      "time for loop  1.906330640998931 avg fps  0.603868657549\n",
      "time for loop  1.614408518998971 avg fps  0.604817816857\n",
      "time for loop  1.5883170230008545 avg fps  0.606221310683\n",
      "time for loop  1.4884504099973128 avg fps  0.609528668828\n",
      "time for loop  1.501458882001316 avg fps  0.612261862703\n",
      "time for loop  1.56703192599889 avg fps  0.613506240911\n",
      "time for loop  1.3194747130000906 avg fps  0.619122389401\n",
      "time for loop  1.4638804690002871 avg fps  0.621769965792\n",
      "time for loop  1.459885623997252 avg fps  0.624274854136\n",
      "time for loop  1.5343658909987425 avg fps  0.625372746993\n",
      "time for loop  1.5235748599989165 avg fps  0.626555628998\n",
      "time for loop  1.500129811000079 avg fps  0.628006934248\n",
      "time for loop  1.6679242169993813 avg fps  0.626904789792\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"parser = argparse.ArgumentParser(\n",
    "        description='Monocular Obstacle Avoidance')\n",
    "    parser.add_argument('--thresh', '-t', type=float, default=0.25,\n",
    "                        help='Sets the distance threshold for match filtering')\n",
    "    parser.add_argument('--debug', '-d', type=str, default=False,\n",
    "                        help='Sets real time camera.')\n",
    "    parser.add_argument('--skip', '-s', type=int, default=0,\n",
    "                        help='Sets number of frames to skip for processing')\n",
    "    parser.add_argument('--video', '-v', type=str, default=\"1.mp4\",\n",
    "                        help='Specifies the video to use for testing.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \"\"\"\n",
    "    # for camera testing pass actual fps of camera instead of skip\n",
    "    # test_on_camera(args.thresh, args.skip, args.debug)\n",
    "\n",
    "    # for video testing the skip arg will decide obstacle speed, because total time since template capture is used\n",
    "    # to calculate the speed of obstacle.\n",
    "    test_on_video('raid.mp4',0.25,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_output = '/Users/dhruvarora/gt-cp-2017-project/visual_looming/output/output.mp4'\n",
    "#clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"/Users/dhruvarora/gt-cp-2017-project/visual_looming/1.mp4\")\n",
    "white_clip = clip1.fl_image(test.process_next_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
